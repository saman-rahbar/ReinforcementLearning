{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandits and Exploration/Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will cover the following subjects:\n",
    "* Implementation of bandit algorithm\n",
    "* The effect of epsilon on exploration and exploitation and the exploration/exploitation tradeoffs\n",
    "* Some tips and tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from rlglue.rl_glue import RLGlue\n",
    "import main_agent\n",
    "import ten_arm_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create an agent that will find the action with the highest expected reward. One way an agent could operate is to always choose the action with the highest value based on the agent’s current estimates. This is called a greedy agent as it greedily chooses the action that it thinks has the highest value. Let's look at what happens in this case.\n",
    "\n",
    "First we are going to implement the argmax function, which takes in a list of action values and returns an action with the highest value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# Graded Cell\n",
    "# -----------\n",
    "def argmax(q_values):\n",
    "    \"\"\"\n",
    "    Takes in a list of q_values and returns the index of the item \n",
    "    with the highest value. Breaks ties randomly.\n",
    "    returns: int - the index of the highest value in q_values\n",
    "    \"\"\"\n",
    "    top_value = float(\"-inf\")\n",
    "    ties = []\n",
    "    \n",
    "    for i in range(len(q_values)):\n",
    "        # if a value in q_values is greater than the highest value update top and reset ties to zero\n",
    "        # if a value is equal to top value add the index to ties\n",
    "        # return a random selection from ties.\n",
    "        ### BEGIN SOLUTION (~5-7 lines)\n",
    "        if q_values[i] > top_value:\n",
    "            top_value = q_values[i]\n",
    "            ties = [i]\n",
    "        elif q_values[i] == top_value:\n",
    "            ties.append(i)\n",
    "        ### END SOLUTION\n",
    "    return np.random.choice(ties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Debugging Cell\n",
    "# --------------\n",
    "# Feel free to make any changes to this cell to debug your code\n",
    "\n",
    "test_array = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "assert argmax(test_array) == 8, \"Check your argmax implementation returns the index of the largest value\"\n",
    "\n",
    "# make sure np.random.choice is called correctly\n",
    "np.random.seed(0)\n",
    "test_array = [1, 0, 0, 1]\n",
    "\n",
    "assert argmax(test_array) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# Tested Cell\n",
    "# -----------\n",
    "# The contents of the cell will be tested by the autograder.\n",
    "# If they do not pass here, they will not pass there.\n",
    "\n",
    "test_array = [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "assert argmax(test_array) == 8, \"Check your argmax implementation returns the index of the largest value\"\n",
    "\n",
    "# set random seed so results are deterministic\n",
    "np.random.seed(0)\n",
    "test_array = [1, 0, 0, 1]\n",
    "\n",
    "counts = [0, 0, 0, 0]\n",
    "for _ in range(100):\n",
    "    a = argmax(test_array)\n",
    "    counts[a] += 1\n",
    "\n",
    "# make sure argmax does not always choose first entry\n",
    "assert counts[0] != 100, \"Make sure your argmax implementation randomly choooses among the largest values.\"\n",
    "\n",
    "# make sure argmax does not always choose last entry\n",
    "assert counts[3] != 100, \"Make sure your argmax implementation randomly choooses among the largest values.\"\n",
    "\n",
    "# make sure the random number generator is called exactly once whenver `argmax` is called\n",
    "expected = [44, 0, 0, 56] # <-- notice not perfectly uniform due to randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we introduce the first part of an RL-Glue agent that you will implement. Here we are going to create a GreedyAgent and implement the agent_step method. This method gets called each time the agent takes a step. The method has to return the action selected by the agent. This method also ensures the agent’s estimates are updated based on the signals it gets from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------\n",
    "# Graded Cell\n",
    "# -----------\n",
    "class GreedyAgent(main_agent.Agent):\n",
    "    def agent_step(self, reward, observation):\n",
    "        \"\"\"\n",
    "        Takes one step for the agent. It takes in a reward and observation and \n",
    "        returns the action the agent chooses at that time step.\n",
    "        \n",
    "        Arguments:\n",
    "        reward -- float, the reward the agent recieved from the environment after taking the last action.\n",
    "        observation -- float, the observed state the agent is in. Do not worry about this as you will not use it\n",
    "                              until future lessons\n",
    "        Returns:\n",
    "        current_action -- int, the action chosen by the agent at the current time step.\n",
    "        \"\"\"\n",
    "        ### Useful Class Variables ###\n",
    "        # self.q_values : An array with what the agent believes each of the values of the arm are.\n",
    "        # self.arm_count : An array with a count of the number of times each arm has been pulled.\n",
    "        # self.last_action : The action that the agent took on the previous time step\n",
    "        #######################\n",
    "        \n",
    "        # Update Q values Hint: Look at the algorithm in section 2.4 of the textbook.\n",
    "        # increment the counter in self.arm_count for the action from the previous time step\n",
    "        # update the step size using self.arm_count\n",
    "        # update self.q_values for the action from the previous time step\n",
    "        \n",
    "        ### BEGIN SOLUTION (~3-5 lines)\n",
    "        self.arm_count[self.last_action] += 1\n",
    "        error = reward - self.q_values[self.last_action]\n",
    "        self.q_values[self.last_action] = self.q_values[self.last_action] + (1/self.arm_count[self.last_action])*(error)\n",
    "        \n",
    "        \n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # current action = ? # Use the argmax function you created above\n",
    "        ### BEGIN SOLUTION (~2 lines)\n",
    "        current_action = argmax(self.q_values)\n",
    "        ### END SOLUTION\n",
    "    \n",
    "        self.last_action = current_action\n",
    "        \n",
    "        return current_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Debugging Cell\n",
    "# --------------\n",
    "# Feel free to make any changes to this cell to debug your code\n",
    "\n",
    "# build a fake agent for testing and set some initial conditions\n",
    "np.random.seed(1)\n",
    "greedy_agent = GreedyAgent()\n",
    "greedy_agent.q_values = [0, 0, 0.5, 0, 0]\n",
    "greedy_agent.arm_count = [0, 1, 0, 0, 0]\n",
    "greedy_agent.last_action = 1\n",
    "\n",
    "action = greedy_agent.agent_step(reward=1, observation=0)\n",
    "\n",
    "# make sure the q_values were updated correctly\n",
    "assert greedy_agent.q_values == [0, 0.5, 0.5, 0, 0]\n",
    "\n",
    "# make sure the agent is using the argmax that breaks ties randomly\n",
    "assert action == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
